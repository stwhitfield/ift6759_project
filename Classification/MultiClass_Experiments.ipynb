{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & Model Loading"
      ],
      "metadata": {
        "id": "FvviBzjQoRi-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vEgubEQBgBE",
        "outputId": "7634a0a6-49a9-4d4a-f346-ea4c18238666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# #@title Mount your Google Drive\n",
        "# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# # you can delete this cell which is specific to Google Colab. You may also\n",
        "# # change the paths for data/logs in Arguments below.\n",
        "# %matplotlib inline\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3vDNYulHBrfw"
      },
      "outputs": [],
      "source": [
        "# #@title Link your assignment folder & install requirements\n",
        "# #@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# # you can delete this cell which is specific to Google Colab. \n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/gdrive/MyDrive/ift6759\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
        "\n",
        "# # Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "   sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# # Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "   warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOcYpETrB98Y",
        "outputId": "d99913bf-15d4-45c9-8ee6-a8edc7f1ecd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchxrayvision in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (1.22.4)\n",
            "Requirement already satisfied: torch>=1 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-image>=0.16 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (0.19.3)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (1.5.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (8.4.0)\n",
            "Requirement already satisfied: requests>=1 in /usr/local/lib/python3.10/dist-packages (from torchxrayvision) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->torchxrayvision) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->torchxrayvision) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=1->torchxrayvision) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=1->torchxrayvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=1->torchxrayvision) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=1->torchxrayvision) (1.26.15)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (23.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (2.25.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.10.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1->torchxrayvision) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1->torchxrayvision) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1->torchxrayvision) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1->torchxrayvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1->torchxrayvision) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1->torchxrayvision) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1->torchxrayvision) (3.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1->torchxrayvision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1->torchxrayvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1->torchxrayvision) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.5.1)\n",
            "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.0)\n",
            "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.3)\n",
            "Requirement already satisfied: websockets<12.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (11.0.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.26.15)\n",
            "Requirement already satisfied: uvicorn<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.22.0)\n",
            "Requirement already satisfied: pydantic<4.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.10.7)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.3)\n",
            "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.65.0)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.10/dist-packages (from lightning) (0.22.0)\n",
            "Requirement already satisfied: dateutils<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.6.12)\n",
            "Requirement already satisfied: packaging<25.0,>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.1)\n",
            "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.3.0)\n",
            "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.14)\n",
            "Requirement already satisfied: lightning-cloud>=0.5.34 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.5.34)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.27.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.4.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.22.4)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.8.0)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n",
            "Requirement already satisfied: fastapi<0.89.0,>=0.69.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.88.0)\n",
            "Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.3)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n",
            "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.4)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.3.4)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning) (2022.7.1)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning) (3.6.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.4)\n",
            "Requirement already satisfied: readchar>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n",
            "Requirement already satisfied: python-editor>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n",
            "Requirement already satisfied: blessed>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (1.16.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (0.0.6)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (2.6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (16.0.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<2.0->lightning) (0.14.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torchxrayvision\n",
        "!pip3 install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WtyvkS5yCFKh"
      },
      "outputs": [],
      "source": [
        "import torchxrayvision as xrv # for chest xray pretrained models\n",
        "import skimage, torch, torchvision\n",
        "import torchvision.models as models # for general pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FNit2xmwCIaR"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "from skimage.io import imread\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import tqdm\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorboard\n",
        "import torchmetrics\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from torch import optim, nn, utils, Tensor\n",
        "from torchvision.transforms import ToTensor\n",
        "import lightning.pytorch as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEKBRcbCCTZV",
        "outputId": "e8f808b4-e0bd-4962-9972-9992bfaac6b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import warnings\n",
        "if not torch.cuda.is_available():\n",
        "    warnings.warn('CUDA is not available')\n",
        "    use_gpu = False\n",
        "    device = torch.device('cpu')\n",
        "else:\n",
        "    use_gpu = True\n",
        "    device = torch.device('cuda:0')\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J4A8Y0UsCUq1"
      },
      "outputs": [],
      "source": [
        "# What is the task ('classification' or 'regression')\n",
        "task = 'classification'\n",
        "# If classification, how many classes?\n",
        "if task == 'classification':\n",
        "    final_out_features = 3\n",
        "# If regression, final out features is 1\n",
        "elif task == 'regression':\n",
        "    final_out_features = 1\n",
        "# What level of dropout do we want for the adaptor (classifier/regressor) head of the model?\n",
        "head_dropout = 0.5\n",
        "# Are we using a pretrained model from torchxrayvision?\n",
        "from_xrv = False\n",
        "# What is the model name?\n",
        "#     pretrained models from torchxrayvision:\n",
        "# ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', 'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']\n",
        "#     pretrained models from torchvision:\n",
        "# ['alexnet','densenet', 'squeezenet', 'mobilenet', 'vgg16']\n",
        "model_name = 'alexnet'\n",
        "# How many epochs to train for?\n",
        "num_epochs = 300\n",
        "# What optimizer, learning rate and scheduler do we want for training?\n",
        "learning_rate = 0.001\n",
        "optimizer_type = 'AdamW' # Choose from 'SGD' or 'AdamW'\n",
        "# Other train-val-test settings\n",
        "split_lengths = [0.8, 0.0, 0.2]\n",
        "batch_size = 10\n",
        "\n",
        "# Do we want to filter the dataset by chest xray views?\n",
        "view = ['*'] # [other options are ['PA', 'AP']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_8R2INUxCZwC"
      },
      "outputs": [],
      "source": [
        "class LightningRegressor(pl.LightningModule):\n",
        "    def __init__(self,model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.mse = torchmetrics.MeanSquaredError()\n",
        "        self.mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.r2_score = torchmetrics.R2Score()\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        # print(f'y: {y}')\n",
        "        # Make prediction\n",
        "        x = self.model(x)\n",
        "        # print(f'x {x}')\n",
        "        # Calculate and log loss\n",
        "        loss = nn.functional.mse_loss(x,y)\n",
        "        mean_squared_error = self.mse(x,y)\n",
        "        mean_absolute_error = self.mae(x,y)\n",
        "        r2_score = self.r2_score(x,y)\n",
        "        to_log = {\"train_loss\": loss, \n",
        "                  \"train_mse\": mean_squared_error, \n",
        "                  \"train_mae\": mean_absolute_error,\n",
        "                  'train_r2_score': r2_score}  # add more items if needed\n",
        "        self.log_dict(to_log)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        # Make prediction\n",
        "        x = self.model(x)\n",
        "        # Calculate and log loss\n",
        "        loss = nn.functional.mse_loss(x,y)\n",
        "        mean_squared_error = self.mse(x,y)\n",
        "        mean_absolute_error = self.mae(x,y)        \n",
        "        r2_score = self.r2_score(x,y)\n",
        "        to_log = {\"val_loss\": loss, \n",
        "                  \"val_mse\": mean_squared_error,\n",
        "                  \"val_mae\": mean_absolute_error,\n",
        "                  'val_r2_score': r2_score}  # add more items if needed\n",
        "        self.log_dict(to_log)\n",
        "        return loss\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        # Make prediction\n",
        "        x = self.model(x)\n",
        "        # Calculate and log loss\n",
        "        loss = nn.functional.mse_loss(x,y)\n",
        "        mean_squared_error = self.mse(x,y)\n",
        "        mean_absolute_error = self.mae(x,y)        \n",
        "        r2_score = self.r2_score(x,y)\n",
        "        to_log = {\"test_loss\": loss, \n",
        "                  \"test_mse\": mean_squared_error, \n",
        "                  \"test_mae\": mean_absolute_error,\n",
        "                  'test_r2_score': r2_score}  # add more items if needed\n",
        "        self.log_dict(to_log)\n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = 1e-3)\n",
        "        return optimizer\n",
        "    \n",
        "class LightningClassifier(pl.LightningModule):\n",
        "    def __init__(self,model, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.auroc = torchmetrics.AUROC(task = 'multiclass', num_classes=num_classes)\n",
        "        self.confusion_matrix = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=3)\n",
        "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.recall = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.specificity = torchmetrics.Specificity(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.validation_step_outputs = []\n",
        "        self.validation_step_targets = []\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        # Make predictions\n",
        "        x = self.model(x)\n",
        "        # Calculate and log loss\n",
        "        loss = self.loss(x,y)\n",
        "        acc = self.acc(x,y)\n",
        "        auroc = self.auroc(x,y)\n",
        "        #confusion_matrix = self.confusion_matrix(x,y)\n",
        "        f1_score = self.f1_score(x,y)\n",
        "        precision = self.precision(x,y)\n",
        "        recall = self.recall(x,y)\n",
        "        specificity = self.specificity(x,y)\n",
        "        to_log = {'train_loss': loss,\n",
        "                  'train_acc': acc,\n",
        "                  'train_auroc': auroc,\n",
        "                  #'train_confusion_matrix': confusion_matrix,\n",
        "                  'train_f1_score': f1_score ,\n",
        "                  'train_precision': precision,\n",
        "                  'train_recall': recall,\n",
        "                  'train_specificity': specificity,\n",
        "                  }  # add more items if needed\n",
        "        #print(to_log)\n",
        "        self.log_dict(to_log)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        # Make predictions\n",
        "        x = self.model(x)\n",
        "\n",
        "        # Calculate and log loss\n",
        "        loss = self.loss(x,y)\n",
        "        acc = self.acc(x,y)\n",
        "        auroc = self.auroc(x,y)\n",
        "        confusion_matrix = self.confusion_matrix(x,y)\n",
        "        f1_score = self.f1_score(x,y)\n",
        "        precision = self.precision(x,y)\n",
        "        recall = self.recall(x,y)\n",
        "        specificity = self.specificity(x,y)\n",
        "        to_log = {'val_loss': loss,\n",
        "                  'val_acc': acc,\n",
        "                  'val_auroc': auroc,\n",
        "                   \n",
        "                  'val_f1_score': f1_score ,\n",
        "                  'val_precision': precision,\n",
        "                  'val_recall': recall,\n",
        "                  'val_specificity': specificity,\n",
        "                  }  # add more items if needed\n",
        "        print(to_log)\n",
        "        self.log_dict(to_log)\n",
        "\n",
        "        return loss\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        #print(y)\n",
        "        # Make predictions\n",
        "        x = self.model(x)\n",
        "        #print(x)\n",
        "        # Calculate and log loss\n",
        "\n",
        "        loss = self.loss(x,y)\n",
        "        acc = self.acc(x,y)\n",
        "        auroc = self.auroc(x,y)\n",
        "        confusion_matrix = self.confusion_matrix(x,y)\n",
        "        f1_score = self.f1_score(x,y)\n",
        "        precision = self.precision(x,y)\n",
        "        recall = self.recall(x,y)\n",
        "        specificity = self.specificity(x,y)\n",
        "        to_log = {\n",
        "            #'pred': x,\n",
        "            #       'gt': y,\n",
        "                  'test_loss': loss,\n",
        "                  'test_acc': acc,\n",
        "                  'test_auroc': auroc,\n",
        "                  #'test_confusion_matrix': str(confusion_matrix),\n",
        "                  'test_f1_score': f1_score ,\n",
        "                  'test_precision': precision,\n",
        "                  'test_recall': recall,\n",
        "                  'test_specificity': specificity,\n",
        "                  }  # add more items if needed\n",
        "        print(to_log)\n",
        "        self.log_dict(to_log)\n",
        "        pred = x \n",
        "        targets = y \n",
        "        self.validation_step_outputs.append(pred)\n",
        "        self.validation_step_targets.append(targets)\n",
        "        return pred, targets\n",
        "    \n",
        "    #def on_test_epoch_end(self):\n",
        "        \n",
        "    #    validation_step_outputs = torch.cat(self.validation_step_outputs)\n",
        "    #    validation_step_targets = torch.cat(self.validation_step_targets)\n",
        "\n",
        "        #confusion = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=3)#.to(device='cpu')\n",
        "     #   cm = self.confusion_matrix(validation_step_outputs, validation_step_targets)\n",
        "     #   print(cm)\n",
        "     #   print((validation_step_targets))\n",
        "     #   print((validation_step_outputs[0].cpu().numpy().argmax()))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = 1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "53cOPa5lCgHN"
      },
      "outputs": [],
      "source": [
        "class CovidSeverity_Dataset(Dataset):\n",
        "    def __init__(self, img_dir, annotations_file, from_xrv = False, transform = None, views = ['*'], data_aug = False, task = 'regression'):\n",
        "        self.image_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.from_xrv = from_xrv\n",
        "        self.views = views\n",
        "        self.data_aug = data_aug\n",
        "        self.task = task\n",
        "\n",
        "        # Load data labels\n",
        "        self.csv = pd.read_csv(annotations_file, index_col=0).reset_index()\n",
        "        \n",
        "        # Set the labels based on the task\n",
        "        if self.task == 'regression':\n",
        "            self.image_labels = self.csv['OpacityScoreGlobal']\n",
        "        elif self.task == 'classification':\n",
        "            self.image_labels = self.csv['OpacityScoreGlobal'].round()\n",
        "            \n",
        "\n",
        "        # Keep only the selected views.\n",
        "        self.limit_to_selected_views(views)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read in the image\n",
        "        image_filename = self.csv['filename'].iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, image_filename)\n",
        "\n",
        "        # If the associated model will be from torchxrayvision, convert to grayscale then normalize\n",
        "        if False: \n",
        "            image = torchvision.io.read_image(image_path, mode = torchvision.io.ImageReadMode.GRAY)\n",
        "        else:\n",
        "            image = torchvision.io.read_image(image_path, mode = torchvision.io.ImageReadMode.RGB)\n",
        "        \n",
        "        # Convert label to tensor\n",
        "        label = self.image_labels[idx]\n",
        "        if self.task == 'regression':\n",
        "            label = torch.tensor(label, dtype = torch.float).unsqueeze(0)\n",
        "        elif self.task == 'classification':\n",
        "            # low\n",
        "            if float(label) < 2.0:\n",
        "              label = 0.0\n",
        "            # moderate \n",
        "            if float(label) >= 2.0 and float(label) < 4.0:\n",
        "              label = 1.0\n",
        "            # severe\n",
        "            if float(label) >= 4.0: \n",
        "              label = 2.0\n",
        "            #print(label)\n",
        "            label = torch.tensor(label).type(torch.LongTensor)   \n",
        "        \n",
        "        # Transform image\n",
        "        if self.transform:\n",
        "            image = self.transform(image.type(torch.uint8))\n",
        "        # Apply data augmentation if specified\n",
        "        if self.data_aug:\n",
        "            image = self.data_aug(image)\n",
        "        \n",
        "        if self.from_xrv:\n",
        "            image = (image - 127.5) / 127.5 * 1024 # Scales the image to between approx -1024 and 1024, from 0-255\n",
        "        \n",
        "        return image.type(torch.float32), label\n",
        "    \n",
        "    def limit_to_selected_views(self, views):\n",
        "        \"\"\"Filters the images by view based on the values in .csv['view']\n",
        "        \"\"\"\n",
        "        if type(views) is not list:\n",
        "            views = [views]\n",
        "        if '*' in views:\n",
        "            # if you have the wildcard, the rest are irrelevant\n",
        "            views = [\"*\"]\n",
        "        self.views = views\n",
        "\n",
        "        # missing data is unknown\n",
        "        self.csv.view.fillna(\"UNKNOWN\", inplace=True)\n",
        "\n",
        "        if \"*\" not in views:\n",
        "            self.csv = self.csv[self.csv[\"view\"].isin(self.views)]  # Select the view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gskoQ9mTCkzZ"
      },
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(30),      # rotate +/- 30 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # rHorizontally flip the given image randomly with a given probability (default p=0.5)\n",
        "    transforms.RandomAutocontrast(p=0.5),\n",
        "    transforms.RandomEqualize(p=0.5),\n",
        "    transforms.CenterCrop(224),\n",
        "    ])\n",
        "\n",
        "data_aug = False\n",
        "\n",
        "# Set up dataset\n",
        "# If on colab\n",
        "combined_labels = \"/content/gdrive/MyDrive/processed_images/data_processing/final_combined_cxr_metadata.csv\"\n",
        "processed_images = \"/content/gdrive/MyDrive/processed_images\"\n",
        "\n",
        "# otherwise\n",
        "#combined_labels = \"./data_processing/combined_cxr_metadata.csv\"\n",
        "#processed_images = \"./processed_images\"\n",
        "\n",
        "dataset = CovidSeverity_Dataset(processed_images, \n",
        "                                combined_labels, \n",
        "                                from_xrv = from_xrv, # defined above, cell 10\n",
        "                                transform = transform,\n",
        "                                views = view, # defined above, cell 10\n",
        "                                data_aug = data_aug, \n",
        "                                task = task # defined above, cell 10\n",
        "                                )\n",
        "\n",
        "# Split dataset into train, val, test\n",
        "# Split lengths and batch size are defined above\n",
        "\n",
        "train_split, val_split, test_split = random_split(dataset= dataset, \n",
        "                                                 lengths = split_lengths, # defined above, cell 10\n",
        "                                                 generator = torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(train_split, batch_size = batch_size, shuffle = True)\n",
        "#val_loader = DataLoader(val_split, batch_size = batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_split, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMlNRYIUCpK_",
        "outputId": "72085f97-c5a8-470f-cb87-a357430b730b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7162"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(dataset) # 1432"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jdrFnfOcDJAQ"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):\n",
        "    \"\"\"\n",
        "    Loads a model from torchxrayvision or torchvision\n",
        "    \"\"\"\n",
        "    # Set the chosen model as \"model\"\n",
        "    # From torchxrayvision\n",
        "    ## 224x224 models\n",
        "    if model_name == 'densenet_all':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    elif model_name == 'densenet_rsna':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-rsna\") # RSNA Pneumonia Challenge\n",
        "    elif model_name == 'densenet_nih':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-nih\") # NIH chest X-ray8\n",
        "    elif model_name == 'densenet_pc':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-pc\") # PadChest (University of Alicante)\n",
        "    elif model_name == 'densenet_chex':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\") # CheXpert (Stanford)\n",
        "    elif model_name == 'densenet_mimic_nb':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_nb\") # MIMIC-CXR (MIT)\n",
        "    elif model_name == 'densenet_mimic_ch':\n",
        "        model = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_ch\") # MIMIC-CXR (MIT)\n",
        "\n",
        "    # from torchvision\n",
        "    elif model_name == 'densenet':\n",
        "        model = models.densenet161(pretrained=True) # torchvision densenet pretrained on imagenet\n",
        "    elif model_name == 'alexnet':\n",
        "        model = models.alexnet(pretrained=True) \n",
        "    elif model_name == 'squeezenet':\n",
        "        model = models.squeezenet1_0(pretrained=True)\n",
        "    elif model_name == 'mobilenet':\n",
        "        model = models.mobilenet_v2(pretrained=True)\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "    return model\n",
        "\n",
        "model_name=('densenet')\n",
        "model = load_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UZbUFul3DLzZ"
      },
      "outputs": [],
      "source": [
        "def adapt_model(model, model_name = 'densenet_all', task = 'regression', final_out_features = 1):\n",
        "    \"\"\"\n",
        "    Adapt a model by changing the classification head\n",
        "    \"\"\"\n",
        "    # If the model name is one of the following, it is from torchxrayvision\n",
        "    if model_name in ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', \n",
        "                      'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']:\n",
        "        from_xrv = True\n",
        "        print('here')\n",
        "    \n",
        "    # Make a deep copy of the model\n",
        "    model = copy.deepcopy(model)\n",
        "    \n",
        "    # Freeze weights in model\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Get number of features flowing into the classifier layer we want to change\n",
        "    # If the model is a densenet-161-based model (all of xrv, or densenet from torchvision)\n",
        "    if model_name in ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', \n",
        "                      'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']:\n",
        "        # The classifier is named 'classifier'\n",
        "        in_features = model.classifier.in_features\n",
        "        hidden_features = int(in_features/2) # note: this constriction was largely arbitrarily-decided\n",
        "        \n",
        "        # Kludge on an extra part after self.classifier. xrv gets snippy if you just try to change the classifier itself.\n",
        "        extra = nn.Sequential(\n",
        "            nn.Linear(18,hidden_features), # an xrv model outputs 18 features\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_features,final_out_features)\n",
        "        )\n",
        "        model = nn.Sequential(model,extra)\n",
        "\n",
        "    # If the model is one of the following, it can be accessed by .classifier[-1]\n",
        "    elif model_name in ['alexnet', 'mobilenet', 'vgg16'] :\n",
        "        in_features = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(in_features, final_out_features)\n",
        "        \n",
        "    elif model_name in ['squeezenet'] :\n",
        "        in_features = model.classifier[-1].in_features\n",
        "        model.classifier.append(nn.Linear(1000, final_out_features))\n",
        "\n",
        "    elif model_name == 'densenet':\n",
        "        in_features = model.classifier.in_features\n",
        "        hidden_features = int(in_features/2) # note: this constriction was largely arbitrarily-decided\n",
        "        # Kludge on an extra part after self.classifier, to be comparable with xrv models\n",
        "        extra = nn.Sequential(\n",
        "            nn.Linear(1000,hidden_features), # an xrv model outputs 18 features\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_features,final_out_features)\n",
        "        )\n",
        "        model = nn.Sequential(model,extra)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o6S4BhZlDRdt"
      },
      "outputs": [],
      "source": [
        "model = adapt_model(model, model_name = model_name, task = task, final_out_features = final_out_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examining the DenseNet out of Box"
      ],
      "metadata": {
        "id": "Uh_F1V1Jno6A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_K1soIEDTqF",
        "outputId": "74cc97d3-ae51-4435-bbda-ddf58e8ccdfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): DenseNet(\n",
              "    (features): Sequential(\n",
              "      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu0): ReLU(inplace=True)\n",
              "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (denseblock1): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition1): _Transition(\n",
              "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock2): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition2): _Transition(\n",
              "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock3): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer17): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer18): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer19): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer20): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer21): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer22): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer23): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer24): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer25): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer26): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer27): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer28): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer29): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer30): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer31): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer32): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer33): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer34): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer35): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer36): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (transition3): _Transition(\n",
              "        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (denseblock4): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer17): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer18): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer19): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer20): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer21): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer22): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer23): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer24): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): Linear(in_features=1000, out_features=1104, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1104, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model\n",
        "#CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MKGJuHkmDV2A"
      },
      "outputs": [],
      "source": [
        "# Initialize the model with pytorch lightning module\n",
        "num_classes = 3\n",
        "if task == 'classification':\n",
        "    lightning_model = LightningClassifier(model, num_classes)\n",
        "elif task == 'regression':\n",
        "    lightning_model = LightningRegressor(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ldOwshwhsh",
        "outputId": "036d913e-87c5-41a3-afe8-638b279e6d4d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813,
          "referenced_widgets": [
            "ddbc0979e1934756bab270599eac08ae",
            "abf25bf79794417ba5a197329966765e",
            "ee9a8d3f92074ab28ed92d9ea1758f97",
            "01509c103fa64126b046ea9f3173faec",
            "0dbb9c8525cc4e05a84edd7824382588",
            "74693f70bb69473eb4b11233316c8f7f",
            "7a2a264bbb87488ba323f95c30158f6e",
            "dee9085827224244858da155e96e9058",
            "f623f78d976449af973b4a392df0e7cb",
            "f53678ad58964e30b39a402aa62689ab",
            "65a17d00e9684253b42359c167e02c38"
          ]
        },
        "id": "FPzhFm82De_U",
        "outputId": "5745564a-1518-4701-a4b1-592e40f30641"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name             | Type                      | Params\n",
            "---------------------------------------------------------------\n",
            "0 | model            | Sequential                | 29.8 M\n",
            "1 | loss             | CrossEntropyLoss          | 0     \n",
            "2 | acc              | MulticlassAccuracy        | 0     \n",
            "3 | auroc            | MulticlassAUROC           | 0     \n",
            "4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n",
            "5 | f1_score         | MulticlassF1Score         | 0     \n",
            "6 | precision        | MulticlassPrecision       | 0     \n",
            "7 | recall           | MulticlassRecall          | 0     \n",
            "8 | specificity      | MulticlassSpecificity     | 0     \n",
            "---------------------------------------------------------------\n",
            "3.3 M     Trainable params\n",
            "26.5 M    Non-trainable params\n",
            "29.8 M    Total params\n",
            "119.158   Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name             | Type                      | Params\n",
            "---------------------------------------------------------------\n",
            "0 | model            | Sequential                | 29.8 M\n",
            "1 | loss             | CrossEntropyLoss          | 0     \n",
            "2 | acc              | MulticlassAccuracy        | 0     \n",
            "3 | auroc            | MulticlassAUROC           | 0     \n",
            "4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n",
            "5 | f1_score         | MulticlassF1Score         | 0     \n",
            "6 | precision        | MulticlassPrecision       | 0     \n",
            "7 | recall           | MulticlassRecall          | 0     \n",
            "8 | specificity      | MulticlassSpecificity     | 0     \n",
            "---------------------------------------------------------------\n",
            "3.3 M     Trainable params\n",
            "26.5 M    Non-trainable params\n",
            "29.8 M    Total params\n",
            "119.158   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbc0979e1934756bab270599eac08ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# max train batches can be used \n",
        "trainer = pl.Trainer(#limit_train_batches = 100, \n",
        "                     max_epochs = 1,\n",
        "                     accelerator = 'auto',\n",
        "                     enable_checkpointing = True,\n",
        "                    #logger = logger,\n",
        "#                     fast_dev_run = True # runs only one train/val to check code executes ok\n",
        "                    )\n",
        "trainer.fit(model = lightning_model, \n",
        "            train_dataloaders = train_loader,\n",
        "            #val_dataloaders = val_loader,\n",
        "           )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "J8vEkYAuoKTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zaavywf0Dg_L"
      },
      "outputs": [],
      "source": [
        "trainer.test(dataloaders=test_loader)\n",
        "#len(test_loader) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGN16"
      ],
      "metadata": {
        "id": "tvJsVfiG1fEN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6ejIO3e0Ci1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c68a063-78c0-4779-a54f-7fad8516e814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "\n",
            "  0%|          | 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "  2%|         | 8.70M/528M [00:00<00:05, 90.9MB/s]\u001b[A\n",
            "  8%|         | 43.4M/528M [00:00<00:02, 251MB/s] \u001b[A\n",
            " 15%|        | 78.2M/528M [00:00<00:01, 303MB/s]\u001b[A\n",
            " 21%|        | 109M/528M [00:00<00:01, 313MB/s] \u001b[A\n",
            " 26%|       | 139M/528M [00:00<00:01, 305MB/s]\u001b[A\n",
            " 32%|      | 168M/528M [00:00<00:01, 299MB/s]\u001b[A\n",
            " 37%|      | 197M/528M [00:01<00:04, 71.3MB/s]\u001b[A\n",
            " 41%|      | 217M/528M [00:01<00:03, 84.5MB/s]\u001b[A\n",
            " 45%|     | 237M/528M [00:02<00:06, 46.2MB/s]\u001b[A\n",
            " 48%|     | 255M/528M [00:02<00:05, 56.9MB/s]\u001b[A\n",
            " 51%|     | 270M/528M [00:03<00:07, 36.1MB/s]\u001b[A\n",
            " 53%|    | 281M/528M [00:04<00:10, 25.4MB/s]\u001b[A\n",
            " 55%|    | 291M/528M [00:05<00:08, 30.0MB/s]\u001b[A\n",
            " 57%|    | 300M/528M [00:07<00:19, 12.5MB/s]\u001b[A\n",
            " 58%|    | 306M/528M [00:08<00:22, 10.4MB/s]\u001b[A\n",
            " 59%|    | 312M/528M [00:08<00:18, 12.5MB/s]\u001b[A\n",
            " 60%|    | 317M/528M [00:10<00:25, 8.68MB/s]\u001b[A\n",
            " 61%|    | 321M/528M [00:10<00:25, 8.56MB/s]\u001b[A\n",
            " 61%|   | 324M/528M [00:10<00:23, 9.04MB/s]\u001b[A\n",
            " 62%|   | 326M/528M [00:11<00:28, 7.44MB/s]\u001b[A\n",
            " 62%|   | 328M/528M [00:11<00:26, 7.90MB/s]\u001b[A\n",
            " 63%|   | 331M/528M [00:11<00:20, 10.0MB/s]\u001b[A\n",
            " 63%|   | 333M/528M [00:12<00:27, 7.47MB/s]\u001b[A\n",
            " 63%|   | 335M/528M [00:12<00:31, 6.34MB/s]\u001b[A\n",
            " 64%|   | 336M/528M [00:13<00:32, 6.13MB/s]\u001b[A\n",
            " 65%|   | 343M/528M [00:13<00:15, 12.6MB/s]\u001b[A\n",
            " 66%|   | 349M/528M [00:13<00:09, 19.4MB/s]\u001b[A\n",
            " 67%|   | 354M/528M [00:13<00:07, 24.0MB/s]\u001b[A\n",
            " 68%|   | 358M/528M [00:14<00:16, 10.6MB/s]\u001b[A\n",
            " 69%|   | 365M/528M [00:14<00:10, 16.5MB/s]\u001b[A\n",
            " 70%|   | 370M/528M [00:15<00:18, 8.81MB/s]\u001b[A\n",
            " 71%|   | 373M/528M [00:16<00:20, 7.81MB/s]\u001b[A\n",
            " 73%|  | 386M/528M [00:16<00:09, 16.6MB/s]\u001b[A\n",
            " 74%|  | 391M/528M [00:17<00:12, 11.5MB/s]\u001b[A\n",
            " 76%|  | 403M/528M [00:17<00:06, 19.1MB/s]\u001b[A\n",
            " 78%|  | 409M/528M [00:18<00:09, 13.3MB/s]\u001b[A\n",
            " 80%|  | 420M/528M [00:18<00:05, 20.0MB/s]\u001b[A\n",
            " 81%|  | 426M/528M [00:19<00:08, 12.8MB/s]\u001b[A\n",
            " 87%| | 461M/528M [00:19<00:02, 34.5MB/s]\u001b[A\n",
            " 94%|| 494M/528M [00:19<00:00, 60.4MB/s]\u001b[A\n",
            "100%|| 528M/528M [00:19<00:00, 27.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_name=('vgg16')\n",
        "model = load_model(model_name)\n",
        "model = adapt_model(model, model_name = model_name, task = task, final_out_features = final_out_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "UQMSgazs_Wi7",
        "outputId": "56b1fb5f-6c41-41f8-99ab-06acb221d8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    558\u001b[0m         )\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;31m# strategy will configure model and move it to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/single_device.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/single_device.py\u001b[0m in \u001b[0;36mmodel_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"self.model must be set before self.model.to()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/device_dtype_mixin.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-16aae19f2763>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                     fast_dev_run = True # runs only one train/val to check code executes ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     )\n\u001b[0;32m----> 8\u001b[0;31m trainer.fit(model = lightning_model, \n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#val_dataloaders = val_loader,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\n\u001b[1;32m    957\u001b[0m         Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/accelerators/cuda.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0m_clear_cuda_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/fabric/accelerators/cuda.py\u001b[0m in \u001b[0;36m_clear_cuda_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/95668\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_clearCublasWorkspaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "trainer = pl.Trainer(#limit_train_batches = 300, \n",
        "                     max_epochs = 1,\n",
        "                     accelerator = 'auto',\n",
        "                     enable_checkpointing = True,\n",
        "#                     fast_dev_run = True # runs only one train/val to check code executes ok\n",
        "                    )\n",
        "trainer.fit(model = lightning_model, \n",
        "            train_dataloaders = train_loader,\n",
        "            #val_dataloaders = val_loader,\n",
        "           )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PHadYxPSvIq"
      },
      "source": [
        "## Standalone Confusion Matrix (with Untrained Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hta3hBws_gcC"
      },
      "outputs": [],
      "source": [
        "trainer.test(dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiJJV7hpJszU",
        "outputId": "d5191bce-7138-4a97-cab0-91be1ed0cbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0.,   18.,    0.],\n",
            "        [   0., 1094.,    0.],\n",
            "        [   0.,  320.,    0.]])\n"
          ]
        }
      ],
      "source": [
        "nb_classes = 3\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_loader):\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4qlMqPTLIvX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddbc0979e1934756bab270599eac08ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abf25bf79794417ba5a197329966765e",
              "IPY_MODEL_ee9a8d3f92074ab28ed92d9ea1758f97",
              "IPY_MODEL_01509c103fa64126b046ea9f3173faec"
            ],
            "layout": "IPY_MODEL_0dbb9c8525cc4e05a84edd7824382588"
          }
        },
        "abf25bf79794417ba5a197329966765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74693f70bb69473eb4b11233316c8f7f",
            "placeholder": "",
            "style": "IPY_MODEL_7a2a264bbb87488ba323f95c30158f6e",
            "value": "Epoch 0:  52%"
          }
        },
        "ee9a8d3f92074ab28ed92d9ea1758f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee9085827224244858da155e96e9058",
            "max": 573,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f623f78d976449af973b4a392df0e7cb",
            "value": 300
          }
        },
        "01509c103fa64126b046ea9f3173faec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f53678ad58964e30b39a402aa62689ab",
            "placeholder": "",
            "style": "IPY_MODEL_65a17d00e9684253b42359c167e02c38",
            "value": " 300/573 [36:25&lt;33:08,  7.28s/it, v_num=12]"
          }
        },
        "0dbb9c8525cc4e05a84edd7824382588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "74693f70bb69473eb4b11233316c8f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2a264bbb87488ba323f95c30158f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee9085827224244858da155e96e9058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f623f78d976449af973b4a392df0e7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f53678ad58964e30b39a402aa62689ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a17d00e9684253b42359c167e02c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{"cells":[{"cell_type":"markdown","source":["# Dataset & Model Loading"],"metadata":{"id":"FvviBzjQoRi-"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21075,"status":"ok","timestamp":1682704266652,"user":{"displayName":"lucia berger","userId":"03487606388236985639"},"user_tz":240},"id":"1vEgubEQBgBE","outputId":"c9672b1d-031b-4251-e6e3-6f5d1cd5fe59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["# #@title Mount your Google Drive\n","# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n","# # you can delete this cell which is specific to Google Colab. You may also\n","# # change the paths for data/logs in Arguments below.\n","# %matplotlib inline\n","# %load_ext autoreload\n","# %autoreload 2\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vDNYulHBrfw"},"outputs":[],"source":["# #@title Link your assignment folder & install requirements\n","# #@markdown Enter the path to the assignment folder in your Google Drive\n","# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n","# # you can delete this cell which is specific to Google Colab. \n","import sys\n","import os\n","import shutil\n","import warnings\n","\n","folder = \"/content/gdrive/MyDrive/ift6759\" #@param {type:\"string\"}\n","!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n","\n","# # Add the assignment folder to Python path\n","if '/content/assignment' not in sys.path:\n","   sys.path.insert(0, '/content/assignment')\n","\n","# # Check if CUDA is available\n","import torch\n","if not torch.cuda.is_available():\n","   warnings.warn('CUDA is not available.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOcYpETrB98Y"},"outputs":[],"source":["!pip3 install torchxrayvision\n","!pip3 install lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtyvkS5yCFKh"},"outputs":[],"source":["import torchxrayvision as xrv # for chest xray pretrained models\n","import skimage, torch, torchvision\n","import torchvision.models as models # for general pretrained models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNit2xmwCIaR"},"outputs":[],"source":["import copy\n","import os\n","from skimage.io import imread\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorboard\n","import torchmetrics\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from torch import optim, nn, utils, Tensor\n","from torchvision.transforms import ToTensor\n","import lightning.pytorch as pl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1682704302119,"user":{"displayName":"lucia berger","userId":"03487606388236985639"},"user_tz":240},"id":"HEKBRcbCCTZV","outputId":"cf99cf12-5298-49c5-b4e4-96eedb5f4eb3"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import warnings\n","if not torch.cuda.is_available():\n","    warnings.warn('CUDA is not available')\n","    use_gpu = False\n","    device = torch.device('cpu')\n","else:\n","    use_gpu = True\n","    device = torch.device('cuda:0')\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4A8Y0UsCUq1"},"outputs":[],"source":["# What is the task ('classification' or 'regression')\n","task = 'classification'\n","# If classification, how many classes?\n","if task == 'classification':\n","    final_out_features = 3\n","# If regression, final out features is 1\n","elif task == 'regression':\n","    final_out_features = 1\n","# What level of dropout do we want for the adaptor (classifier/regressor) head of the model?\n","head_dropout = 0.5\n","# Are we using a pretrained model from torchxrayvision?\n","from_xrv = False\n","# What is the model name?\n","#     pretrained models from torchxrayvision:\n","# ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', 'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']\n","#     pretrained models from torchvision:\n","# ['alexnet','densenet', 'squeezenet', 'mobilenet', 'vgg16']\n","model_name = 'alexnet'\n","# How many epochs to train for?\n","num_epochs = 300\n","# What optimizer, learning rate and scheduler do we want for training?\n","learning_rate = 0.001\n","optimizer_type = 'AdamW' # Choose from 'SGD' or 'AdamW'\n","# Other train-val-test settings\n","split_lengths = [0.8, 0.0, 0.2]\n","batch_size = 100\n","\n","# Do we want to filter the dataset by chest xray views?\n","view = ['*'] # [other options are ['PA', 'AP']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8R2INUxCZwC"},"outputs":[],"source":["class LightningRegressor(pl.LightningModule):\n","    def __init__(self,model):\n","        super().__init__()\n","        self.model = model\n","        self.mse = torchmetrics.MeanSquaredError()\n","        self.mae = torchmetrics.MeanAbsoluteError()\n","        self.r2_score = torchmetrics.R2Score()\n","    \n","    def training_step(self, batch, batch_idx):\n","        x,y = batch\n","        # print(f'y: {y}')\n","        # Make prediction\n","        x = self.model(x)\n","        # print(f'x {x}')\n","        # Calculate and log loss\n","        loss = nn.functional.mse_loss(x,y)\n","        mean_squared_error = self.mse(x,y)\n","        mean_absolute_error = self.mae(x,y)\n","        r2_score = self.r2_score(x,y)\n","        to_log = {\"train_loss\": loss, \n","                  \"train_mse\": mean_squared_error, \n","                  \"train_mae\": mean_absolute_error,\n","                  'train_r2_score': r2_score}  # add more items if needed\n","        self.log_dict(to_log)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x,y = batch\n","        # Make prediction\n","        x = self.model(x)\n","        # Calculate and log loss\n","        loss = nn.functional.mse_loss(x,y)\n","        mean_squared_error = self.mse(x,y)\n","        mean_absolute_error = self.mae(x,y)        \n","        r2_score = self.r2_score(x,y)\n","        to_log = {\"val_loss\": loss, \n","                  \"val_mse\": mean_squared_error,\n","                  \"val_mae\": mean_absolute_error,\n","                  'val_r2_score': r2_score}  # add more items if needed\n","        self.log_dict(to_log)\n","        return loss\n","        \n","    def test_step(self, batch, batch_idx):\n","        x,y = batch\n","        # Make prediction\n","        x = self.model(x)\n","        # Calculate and log loss\n","        loss = nn.functional.mse_loss(x,y)\n","        mean_squared_error = self.mse(x,y)\n","        mean_absolute_error = self.mae(x,y)        \n","        r2_score = self.r2_score(x,y)\n","        to_log = {\"test_loss\": loss, \n","                  \"test_mse\": mean_squared_error, \n","                  \"test_mae\": mean_absolute_error,\n","                  'test_r2_score': r2_score}  # add more items if needed\n","        self.log_dict(to_log)\n","        return loss\n","    \n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr = 1e-3)\n","        return optimizer\n","    \n","class LightningClassifier(pl.LightningModule):\n","    def __init__(self,model, num_classes):\n","        super().__init__()\n","        self.model = model\n","        self.loss = nn.CrossEntropyLoss()\n","        self.acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n","        self.auroc = torchmetrics.AUROC(task = 'multiclass', num_classes=num_classes)\n","        self.confusion_matrix = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=3)\n","        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n","        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n","        self.recall = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes)\n","        self.specificity = torchmetrics.Specificity(task=\"multiclass\", num_classes=num_classes)\n","        self.validation_step_outputs = []\n","        self.validation_step_targets = []\n","    \n","    def training_step(self, batch, batch_idx):\n","        x,y = batch\n","        # Make predictions\n","        x = self.model(x)\n","        # Calculate and log loss\n","        loss = self.loss(x,y)\n","        acc = self.acc(x,y)\n","        auroc = self.auroc(x,y)\n","        #confusion_matrix = self.confusion_matrix(x,y)\n","        f1_score = self.f1_score(x,y)\n","        precision = self.precision(x,y)\n","        recall = self.recall(x,y)\n","        specificity = self.specificity(x,y)\n","        to_log = {'train_loss': loss,\n","                  'train_acc': acc,\n","                  'train_auroc': auroc,\n","                  #'train_confusion_matrix': confusion_matrix,\n","                  'train_f1_score': f1_score ,\n","                  'train_precision': precision,\n","                  'train_recall': recall,\n","                  'train_specificity': specificity,\n","                  }  # add more items if needed\n","        #print(to_log)\n","        self.log_dict(to_log)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x,y = batch\n","        # Make predictions\n","        x = self.model(x)\n","\n","        # Calculate and log loss\n","        loss = self.loss(x,y)\n","        acc = self.acc(x,y)\n","        auroc = self.auroc(x,y)\n","        confusion_matrix = self.confusion_matrix(x,y)\n","        f1_score = self.f1_score(x,y)\n","        precision = self.precision(x,y)\n","        recall = self.recall(x,y)\n","        specificity = self.specificity(x,y)\n","        to_log = {'val_loss': loss,\n","                  'val_acc': acc,\n","                  'val_auroc': auroc,\n","                   \n","                  'val_f1_score': f1_score ,\n","                  'val_precision': precision,\n","                  'val_recall': recall,\n","                  'val_specificity': specificity,\n","                  }  # add more items if needed\n","        print(to_log)\n","        self.log_dict(to_log)\n","\n","        return loss\n","        \n","    def test_step(self, batch, batch_idx):\n","        x,y = batch\n","        #print(y)\n","        # Make predictions\n","        x = self.model(x)\n","        #print(x)\n","        # Calculate and log loss\n","\n","        loss = self.loss(x,y)\n","        acc = self.acc(x,y)\n","        auroc = self.auroc(x,y)\n","        confusion_matrix = self.confusion_matrix(x,y)\n","        f1_score = self.f1_score(x,y)\n","        precision = self.precision(x,y)\n","        recall = self.recall(x,y)\n","        specificity = self.specificity(x,y)\n","        to_log = {\n","            #'pred': x,\n","            #       'gt': y,\n","                  'test_loss': loss,\n","                  'test_acc': acc,\n","                  'test_auroc': auroc,\n","                  #'test_confusion_matrix': str(confusion_matrix),\n","                  'test_f1_score': f1_score ,\n","                  'test_precision': precision,\n","                  'test_recall': recall,\n","                  'test_specificity': specificity,\n","                  }  # add more items if needed\n","        print(to_log)\n","        self.log_dict(to_log)\n","        pred = x \n","        targets = y \n","        self.validation_step_outputs.append(pred)\n","        self.validation_step_targets.append(targets)\n","        return pred, targets\n","    \n","    def on_test_epoch_end(self):\n","        \n","        validation_step_outputs = torch.cat(self.validation_step_outputs)\n","        validation_step_targets = torch.cat(self.validation_step_targets)\n","\n","        #confusion = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=3)#.to(device='cpu')\n","        cm = self.confusion_matrix(validation_step_outputs, validation_step_targets)\n","        print(cm)\n","        print((validation_step_targets))\n","        print((validation_step_outputs[0].cpu().numpy().argmax()))\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr = 1e-3)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53cOPa5lCgHN"},"outputs":[],"source":["class CovidSeverity_Dataset(Dataset):\n","    def __init__(self, img_dir, annotations_file, from_xrv = False, transform = None, views = ['*'], data_aug = False, task = 'regression'):\n","        self.image_dir = img_dir\n","        self.transform = transform\n","        self.from_xrv = from_xrv\n","        self.views = views\n","        self.data_aug = data_aug\n","        self.task = task\n","\n","        # Load data labels\n","        self.csv = pd.read_csv(annotations_file, index_col=0).reset_index()\n","        \n","        # Set the labels based on the task\n","        if self.task == 'regression':\n","            self.image_labels = self.csv['OpacityScoreGlobal']\n","        elif self.task == 'classification':\n","            self.image_labels = self.csv['OpacityScoreGlobal'].round()\n","            \n","\n","        # Keep only the selected views.\n","        self.limit_to_selected_views(views)\n","        \n","    def __len__(self):\n","        return len(self.image_labels)\n","\n","    def __getitem__(self, idx):\n","        # Read in the image\n","        image_filename = self.csv['filename'].iloc[idx]\n","        image_path = os.path.join(self.image_dir, image_filename)\n","\n","        # If the associated model will be from torchxrayvision, convert to grayscale then normalize\n","        if False: \n","            image = torchvision.io.read_image(image_path, mode = torchvision.io.ImageReadMode.GRAY)\n","        else:\n","            image = torchvision.io.read_image(image_path, mode = torchvision.io.ImageReadMode.RGB)\n","        \n","        # Convert label to tensor\n","        label = self.image_labels[idx]\n","        if self.task == 'regression':\n","            label = torch.tensor(label, dtype = torch.float).unsqueeze(0)\n","        elif self.task == 'classification':\n","            if label > 2.0: \n","              label = 1.0\n","            if label > 2.0 and label < 4.0:\n","              label = 2.0\n","            if label > 4.0: \n","              label = 3.0\n","            label = torch.tensor(label).type(torch.LongTensor)   \n","        \n","        # Transform image\n","        if self.transform:\n","            image = self.transform(image.type(torch.uint8))\n","        # Apply data augmentation if specified\n","        if self.data_aug:\n","            image = self.data_aug(image)\n","        \n","        if self.from_xrv:\n","            image = (image - 127.5) / 127.5 * 1024 # Scales the image to between approx -1024 and 1024, from 0-255\n","        \n","        return image.type(torch.float32), label\n","    \n","    def limit_to_selected_views(self, views):\n","        \"\"\"Filters the images by view based on the values in .csv['view']\n","        \"\"\"\n","        if type(views) is not list:\n","            views = [views]\n","        if '*' in views:\n","            # if you have the wildcard, the rest are irrelevant\n","            views = [\"*\"]\n","        self.views = views\n","\n","        # missing data is unknown\n","        self.csv.view.fillna(\"UNKNOWN\", inplace=True)\n","\n","        if \"*\" not in views:\n","            self.csv = self.csv[self.csv[\"view\"].isin(self.views)]  # Select the view"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gskoQ9mTCkzZ"},"outputs":[],"source":["# Define transforms\n","transform = transforms.Compose([\n","    transforms.RandomRotation(30),      # rotate +/- 30 degrees\n","    transforms.RandomHorizontalFlip(),  # rHorizontally flip the given image randomly with a given probability (default p=0.5)\n","    transforms.RandomAutocontrast(p=0.5),\n","    transforms.RandomEqualize(p=0.5),\n","    transforms.CenterCrop(224),\n","    ])\n","\n","data_aug = False\n","\n","# Set up dataset\n","# If on colab\n","combined_labels = \"/content/gdrive/MyDrive/processed_images/data_processing/final_combined_cxr_metadata.csv\"\n","processed_images = \"/content/gdrive/MyDrive/processed_images\"\n","\n","# otherwise\n","#combined_labels = \"./data_processing/combined_cxr_metadata.csv\"\n","#processed_images = \"./processed_images\"\n","\n","dataset = CovidSeverity_Dataset(processed_images, \n","                                combined_labels, \n","                                from_xrv = from_xrv, # defined above, cell 10\n","                                transform = transform,\n","                                views = view, # defined above, cell 10\n","                                data_aug = data_aug, \n","                                task = task # defined above, cell 10\n","                                )\n","\n","# Split dataset into train, val, test\n","# Split lengths and batch size are defined above\n","\n","train_split, val_split, test_split = random_split(dataset= dataset, \n","                                                 lengths = split_lengths, # defined above, cell 10\n","                                                 generator = torch.Generator().manual_seed(42))\n","\n","train_loader = DataLoader(train_split, batch_size = batch_size, shuffle = True)\n","#val_loader = DataLoader(val_split, batch_size = batch_size, shuffle = True)\n","test_loader = DataLoader(test_split, batch_size = batch_size, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1682705423850,"user":{"displayName":"lucia berger","userId":"03487606388236985639"},"user_tz":240},"id":"mMlNRYIUCpK_","outputId":"3e3aa68f-dffa-401a-ef89-7e21eadc0929"},"outputs":[{"data":{"text/plain":["7162"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["len(dataset) # 1432"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdrFnfOcDJAQ"},"outputs":[],"source":["def load_model(model_name):\n","    \"\"\"\n","    Loads a model from torchxrayvision or torchvision\n","    \"\"\"\n","    # Set the chosen model as \"model\"\n","    # From torchxrayvision\n","    ## 224x224 models\n","    if model_name == 'densenet_all':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n","    elif model_name == 'densenet_rsna':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-rsna\") # RSNA Pneumonia Challenge\n","    elif model_name == 'densenet_nih':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-nih\") # NIH chest X-ray8\n","    elif model_name == 'densenet_pc':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-pc\") # PadChest (University of Alicante)\n","    elif model_name == 'densenet_chex':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\") # CheXpert (Stanford)\n","    elif model_name == 'densenet_mimic_nb':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_nb\") # MIMIC-CXR (MIT)\n","    elif model_name == 'densenet_mimic_ch':\n","        model = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_ch\") # MIMIC-CXR (MIT)\n","\n","    # from torchvision\n","    elif model_name == 'densenet':\n","        model = models.densenet161(pretrained=True) # torchvision densenet pretrained on imagenet\n","    elif model_name == 'alexnet':\n","        model = models.alexnet(pretrained=True) \n","    elif model_name == 'squeezenet':\n","        model = models.squeezenet1_0(pretrained=True)\n","    elif model_name == 'mobilenet':\n","        model = models.mobilenet_v2(pretrained=True)\n","    elif model_name == 'vgg16':\n","        model = models.vgg16(pretrained=True)\n","    return model\n","\n","model_name=('densenet')\n","model = load_model(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZbUFul3DLzZ"},"outputs":[],"source":["def adapt_model(model, model_name = 'densenet_all', task = 'regression', final_out_features = 1):\n","    \"\"\"\n","    Adapt a model by changing the classification head\n","    \"\"\"\n","    # If the model name is one of the following, it is from torchxrayvision\n","    if model_name in ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', \n","                      'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']:\n","        from_xrv = True\n","        print('here')\n","    \n","    # Make a deep copy of the model\n","    model = copy.deepcopy(model)\n","    \n","    # Freeze weights in model\n","    for param in model.features.parameters():\n","        param.requires_grad = False\n","    \n","    # Get number of features flowing into the classifier layer we want to change\n","    # If the model is a densenet-161-based model (all of xrv, or densenet from torchvision)\n","    if model_name in ['densenet_all', 'densenet_rsna', 'densenet_nih', 'densenet_pc', \n","                      'densenet_chex', 'densenet_mimic_nb', 'densenet_mimic_ch']:\n","        # The classifier is named 'classifier'\n","        in_features = model.classifier.in_features\n","        hidden_features = int(in_features/2) # note: this constriction was largely arbitrarily-decided\n","        \n","        # Kludge on an extra part after self.classifier. xrv gets snippy if you just try to change the classifier itself.\n","        extra = nn.Sequential(\n","            nn.Linear(18,hidden_features), # an xrv model outputs 18 features\n","            nn.ReLU(),\n","            nn.Linear(hidden_features,final_out_features)\n","        )\n","        model = nn.Sequential(model,extra)\n","\n","    # If the model is one of the following, it can be accessed by .classifier[-1]\n","    elif model_name in ['alexnet', 'mobilenet', 'vgg16'] :\n","        in_features = model.classifier[-1].in_features\n","        model.classifier[-1] = nn.Linear(in_features, final_out_features)\n","        \n","    elif model_name in ['squeezenet'] :\n","        in_features = model.classifier[-1].in_features\n","        model.classifier.append(nn.Linear(1000, final_out_features))\n","\n","    elif model_name == 'densenet':\n","        in_features = model.classifier.in_features\n","        hidden_features = int(in_features/2) # note: this constriction was largely arbitrarily-decided\n","        # Kludge on an extra part after self.classifier, to be comparable with xrv models\n","        extra = nn.Sequential(\n","            nn.Linear(1000,hidden_features), # an xrv model outputs 18 features\n","            nn.ReLU(),\n","            nn.Linear(hidden_features,final_out_features)\n","        )\n","        model = nn.Sequential(model,extra)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6S4BhZlDRdt"},"outputs":[],"source":["model = adapt_model(model, model_name = model_name, task = task, final_out_features = final_out_features)"]},{"cell_type":"markdown","source":["# Examining the DenseNet out of Box"],"metadata":{"id":"Uh_F1V1Jno6A"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1682704515098,"user":{"displayName":"lucia berger","userId":"03487606388236985639"},"user_tz":240},"id":"5_K1soIEDTqF","outputId":"d7873c76-b7d9-4c62-cd97-87aee2731425"},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): DenseNet(\n","    (features): Sequential(\n","      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu0): ReLU(inplace=True)\n","      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (denseblock1): _DenseBlock(\n","        (denselayer1): _DenseLayer(\n","          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer2): _DenseLayer(\n","          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer3): _DenseLayer(\n","          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer4): _DenseLayer(\n","          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer5): _DenseLayer(\n","          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer6): _DenseLayer(\n","          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","      )\n","      (transition1): _Transition(\n","        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","      )\n","      (denseblock2): _DenseBlock(\n","        (denselayer1): _DenseLayer(\n","          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer2): _DenseLayer(\n","          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer3): _DenseLayer(\n","          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer4): _DenseLayer(\n","          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer5): _DenseLayer(\n","          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer6): _DenseLayer(\n","          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer7): _DenseLayer(\n","          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer8): _DenseLayer(\n","          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer9): _DenseLayer(\n","          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer10): _DenseLayer(\n","          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer11): _DenseLayer(\n","          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer12): _DenseLayer(\n","          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","      )\n","      (transition2): _Transition(\n","        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","      )\n","      (denseblock3): _DenseBlock(\n","        (denselayer1): _DenseLayer(\n","          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer2): _DenseLayer(\n","          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer3): _DenseLayer(\n","          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer4): _DenseLayer(\n","          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer5): _DenseLayer(\n","          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer6): _DenseLayer(\n","          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer7): _DenseLayer(\n","          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer8): _DenseLayer(\n","          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer9): _DenseLayer(\n","          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer10): _DenseLayer(\n","          (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer11): _DenseLayer(\n","          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer12): _DenseLayer(\n","          (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer13): _DenseLayer(\n","          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer14): _DenseLayer(\n","          (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer15): _DenseLayer(\n","          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer16): _DenseLayer(\n","          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer17): _DenseLayer(\n","          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer18): _DenseLayer(\n","          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer19): _DenseLayer(\n","          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer20): _DenseLayer(\n","          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer21): _DenseLayer(\n","          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer22): _DenseLayer(\n","          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer23): _DenseLayer(\n","          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer24): _DenseLayer(\n","          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer25): _DenseLayer(\n","          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer26): _DenseLayer(\n","          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer27): _DenseLayer(\n","          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer28): _DenseLayer(\n","          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer29): _DenseLayer(\n","          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer30): _DenseLayer(\n","          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer31): _DenseLayer(\n","          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer32): _DenseLayer(\n","          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer33): _DenseLayer(\n","          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer34): _DenseLayer(\n","          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer35): _DenseLayer(\n","          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer36): _DenseLayer(\n","          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","      )\n","      (transition3): _Transition(\n","        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","      )\n","      (denseblock4): _DenseBlock(\n","        (denselayer1): _DenseLayer(\n","          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer2): _DenseLayer(\n","          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer3): _DenseLayer(\n","          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer4): _DenseLayer(\n","          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer5): _DenseLayer(\n","          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer6): _DenseLayer(\n","          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer7): _DenseLayer(\n","          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer8): _DenseLayer(\n","          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer9): _DenseLayer(\n","          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer10): _DenseLayer(\n","          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer11): _DenseLayer(\n","          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer12): _DenseLayer(\n","          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer13): _DenseLayer(\n","          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer14): _DenseLayer(\n","          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer15): _DenseLayer(\n","          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer16): _DenseLayer(\n","          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer17): _DenseLayer(\n","          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer18): _DenseLayer(\n","          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer19): _DenseLayer(\n","          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer20): _DenseLayer(\n","          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer21): _DenseLayer(\n","          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer22): _DenseLayer(\n","          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer23): _DenseLayer(\n","          (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (denselayer24): _DenseLayer(\n","          (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu1): ReLU(inplace=True)\n","          (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu2): ReLU(inplace=True)\n","          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","      )\n","      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n","  )\n","  (1): Sequential(\n","    (0): Linear(in_features=1000, out_features=1104, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=1104, out_features=3, bias=True)\n","  )\n",")"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKGJuHkmDV2A"},"outputs":[],"source":["# Initialize the model with pytorch lightning module\n","num_classes = 3\n","if task == 'classification':\n","    lightning_model = LightningClassifier(model, num_classes)\n","elif task == 'regression':\n","    lightning_model = LightningRegressor(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":813,"referenced_widgets":["2df9dec6b6444c1a85aa8adc8c0303dd","d581aec50cae40db9bc647d5415f3945","449445e2586c4ae489a3425a838bbe2e","7279f95d11e348538f33fd98558e3d8b","4e060d89c8f4474eaab0b9893584ca80","c114f3ad38c349fe9a04ff257ab57c19","4f5fac19ca5f4ce18d0ecb5f1b9a2b34","0470403fbc664edb9bd744765d944392","2ac5a6afe1b04a9bb9facb4308afb9e2","86a63d7dc67640faa04de9b3a7c9e397","e7e9582d63ea41c49745a923221a8947"]},"id":"FPzhFm82De_U","outputId":"9e392784-ecd0-4568-86be-9d9a15a8da99"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name             | Type                      | Params\n","---------------------------------------------------------------\n","0 | model            | Sequential                | 29.8 M\n","1 | loss             | CrossEntropyLoss          | 0     \n","2 | acc              | MulticlassAccuracy        | 0     \n","3 | auroc            | MulticlassAUROC           | 0     \n","4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n","5 | f1_score         | MulticlassF1Score         | 0     \n","6 | precision        | MulticlassPrecision       | 0     \n","7 | recall           | MulticlassRecall          | 0     \n","8 | specificity      | MulticlassSpecificity     | 0     \n","---------------------------------------------------------------\n","3.3 M     Trainable params\n","26.5 M    Non-trainable params\n","29.8 M    Total params\n","119.158   Total estimated model params size (MB)\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name             | Type                      | Params\n","---------------------------------------------------------------\n","0 | model            | Sequential                | 29.8 M\n","1 | loss             | CrossEntropyLoss          | 0     \n","2 | acc              | MulticlassAccuracy        | 0     \n","3 | auroc            | MulticlassAUROC           | 0     \n","4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n","5 | f1_score         | MulticlassF1Score         | 0     \n","6 | precision        | MulticlassPrecision       | 0     \n","7 | recall           | MulticlassRecall          | 0     \n","8 | specificity      | MulticlassSpecificity     | 0     \n","---------------------------------------------------------------\n","3.3 M     Trainable params\n","26.5 M    Non-trainable params\n","29.8 M    Total params\n","119.158   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2df9dec6b6444c1a85aa8adc8c0303dd","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"]}],"source":["trainer = pl.Trainer(#limit_train_batches = 100, \n","                     max_epochs = num_epochs,\n","                     accelerator = 'auto',\n","                     enable_checkpointing = True,\n","                    #logger = logger,\n","#                     fast_dev_run = True # runs only one train/val to check code executes ok\n","                    )\n","trainer.fit(model = lightning_model, \n","            train_dataloaders = train_loader,\n","            #val_dataloaders = val_loader,\n","           )\n","\n"]},{"cell_type":"markdown","source":["# VGNTT Model "],"metadata":{"id":"J8vEkYAuoKTs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zaavywf0Dg_L"},"outputs":[],"source":["trainer.test(dataloaders=test_loader)\n","#len(test_loader) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r6ejIO3e0Ci1"},"outputs":[],"source":["model_name=('vgg16')\n","model = load_model(model_name)\n","model = adapt_model(model, model_name = model_name, task = task, final_out_features = final_out_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":813,"referenced_widgets":["0cef03b05c3c48e68dcb084a95c8c2c4","a51c5eb279b447b5b785096e9649a674","926d6b92346f4c0489f48d2ed7396ecf","58ceeee08863445e857e033513f00404","d8d91e6aef7841e39ce17eae59a6346e","369512de3137466db4421fddc951eec0","1ca8b83c401446029fa8b8f05c46b51a","64e2733e4e424937b59df9e366dfd16f","cb65d365729742739bfc40436a2b03dd","7944099c62234e0ab55d1b71a5768777","c17c71fc0d084afd9b788c94112491f5"]},"id":"UQMSgazs_Wi7","outputId":"a8c0dedb-ea01-4271-c0cc-3be1fd32ebbf"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name             | Type                      | Params\n","---------------------------------------------------------------\n","0 | model            | VGG                       | 134 M \n","1 | loss             | CrossEntropyLoss          | 0     \n","2 | acc              | MulticlassAccuracy        | 0     \n","3 | auroc            | MulticlassAUROC           | 0     \n","4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n","5 | f1_score         | MulticlassF1Score         | 0     \n","6 | precision        | MulticlassPrecision       | 0     \n","7 | recall           | MulticlassRecall          | 0     \n","8 | specificity      | MulticlassSpecificity     | 0     \n","---------------------------------------------------------------\n","119 M     Trainable params\n","14.7 M    Non-trainable params\n","134 M     Total params\n","537.091   Total estimated model params size (MB)\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name             | Type                      | Params\n","---------------------------------------------------------------\n","0 | model            | VGG                       | 134 M \n","1 | loss             | CrossEntropyLoss          | 0     \n","2 | acc              | MulticlassAccuracy        | 0     \n","3 | auroc            | MulticlassAUROC           | 0     \n","4 | confusion_matrix | MulticlassConfusionMatrix | 0     \n","5 | f1_score         | MulticlassF1Score         | 0     \n","6 | precision        | MulticlassPrecision       | 0     \n","7 | recall           | MulticlassRecall          | 0     \n","8 | specificity      | MulticlassSpecificity     | 0     \n","---------------------------------------------------------------\n","119 M     Trainable params\n","14.7 M    Non-trainable params\n","134 M     Total params\n","537.091   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cef03b05c3c48e68dcb084a95c8c2c4","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Train model\n","trainer = pl.Trainer(limit_train_batches = 300, \n","                     max_epochs = 100,\n","                     accelerator = 'auto',\n","                     enable_checkpointing = True,\n","#                     fast_dev_run = True # runs only one train/val to check code executes ok\n","                    )\n","trainer.fit(model = lightning_model, \n","            train_dataloaders = train_loader,\n","            val_dataloaders = val_loader,\n","           )\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6PHadYxPSvIq"},"source":["## Standalone Confusion Matrix (with Untrained Model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hta3hBws_gcC"},"outputs":[],"source":["trainer.test(dataloaders=test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480783,"status":"ok","timestamp":1682624058387,"user":{"displayName":"lucia berger","userId":"03487606388236985639"},"user_tz":240},"id":"oiJJV7hpJszU","outputId":"d5191bce-7138-4a97-cab0-91be1ed0cbb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[   0.,   18.,    0.],\n","        [   0., 1094.,    0.],\n","        [   0.,  320.,    0.]])\n"]}],"source":["nb_classes = 3\n","confusion_matrix = torch.zeros(nb_classes, nb_classes)\n","\n","with torch.no_grad():\n","    for i, (inputs, classes) in enumerate(test_loader):\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        for t, p in zip(classes.view(-1), preds.view(-1)):\n","                confusion_matrix[t.long(), p.long()] += 1\n","\n","print(confusion_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4qlMqPTLIvX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOCqktsIbXBNPRc/ucuvW6r"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0470403fbc664edb9bd744765d944392":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cef03b05c3c48e68dcb084a95c8c2c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a51c5eb279b447b5b785096e9649a674","IPY_MODEL_926d6b92346f4c0489f48d2ed7396ecf","IPY_MODEL_58ceeee08863445e857e033513f00404"],"layout":"IPY_MODEL_d8d91e6aef7841e39ce17eae59a6346e"}},"1ca8b83c401446029fa8b8f05c46b51a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ac5a6afe1b04a9bb9facb4308afb9e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2df9dec6b6444c1a85aa8adc8c0303dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d581aec50cae40db9bc647d5415f3945","IPY_MODEL_449445e2586c4ae489a3425a838bbe2e","IPY_MODEL_7279f95d11e348538f33fd98558e3d8b"],"layout":"IPY_MODEL_4e060d89c8f4474eaab0b9893584ca80"}},"369512de3137466db4421fddc951eec0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449445e2586c4ae489a3425a838bbe2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0470403fbc664edb9bd744765d944392","max":58,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ac5a6afe1b04a9bb9facb4308afb9e2","value":40}},"4e060d89c8f4474eaab0b9893584ca80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"4f5fac19ca5f4ce18d0ecb5f1b9a2b34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58ceeee08863445e857e033513f00404":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7944099c62234e0ab55d1b71a5768777","placeholder":"","style":"IPY_MODEL_c17c71fc0d084afd9b788c94112491f5","value":" 200/300 [00:34&lt;00:17,  5.72it/s, v_num=2]"}},"64e2733e4e424937b59df9e366dfd16f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7279f95d11e348538f33fd98558e3d8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86a63d7dc67640faa04de9b3a7c9e397","placeholder":"","style":"IPY_MODEL_e7e9582d63ea41c49745a923221a8947","value":" 40/58 [12:53&lt;05:47, 19.33s/it, v_num=4]"}},"7944099c62234e0ab55d1b71a5768777":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a63d7dc67640faa04de9b3a7c9e397":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926d6b92346f4c0489f48d2ed7396ecf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_64e2733e4e424937b59df9e366dfd16f","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb65d365729742739bfc40436a2b03dd","value":200}},"a51c5eb279b447b5b785096e9649a674":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_369512de3137466db4421fddc951eec0","placeholder":"","style":"IPY_MODEL_1ca8b83c401446029fa8b8f05c46b51a","value":"Epoch 0:  67%"}},"c114f3ad38c349fe9a04ff257ab57c19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c17c71fc0d084afd9b788c94112491f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb65d365729742739bfc40436a2b03dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d581aec50cae40db9bc647d5415f3945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c114f3ad38c349fe9a04ff257ab57c19","placeholder":"","style":"IPY_MODEL_4f5fac19ca5f4ce18d0ecb5f1b9a2b34","value":"Epoch 0:  69%"}},"d8d91e6aef7841e39ce17eae59a6346e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e7e9582d63ea41c49745a923221a8947":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}